{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR 서비스 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Google Cloud Vision API 준비하기\n",
    "\n",
    "1. [Google Cloud Console](https://console.cloud.google.com/) 에서 프로젝트를 생성/선택합니다.\n",
    "2. `Cloud Vision API` 를 활성화합니다.\n",
    "3. `Service Account`를 만들고, `JSON` 형식의 키를 다운로드합니다.\n",
    "4. 환경 변수 `GOOGLE_APPLICATION_CREDENTIALS` 로 해당 키 파일의 경로를 등록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google.cloud import vision\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Vision Client 생성\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "IMAGE_PATH = '실습용 이미지 경로 설정'  # TODO: 실습용 이미지 경로 수정\n",
    "\n",
    "with open(IMAGE_PATH, 'rb') as img_file:\n",
    "    content = img_file.read()\n",
    "\n",
    "image = vision.Image(content=content)\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations\n",
    "\n",
    "print('--- 인식된 텍스트 ---')\n",
    "if texts:\n",
    "    print(texts[0].description)\n",
    "else:\n",
    "    print('텍스트가 인식되지 않았습니다.')\n",
    "\n",
    "# 오류 처리\n",
    "if response.error.message:\n",
    "    raise Exception(f'API Error: {response.error.message}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naver CLOVA OCR API 준비하기\n",
    "\n",
    "1. [Naver Cloud Console](https://www.ncloud.com/) 에서 프로젝트를 생성/선택합니다.\n",
    "2. `AI·ML > CLOVA OCR` 서비스를 활성화합니다.\n",
    "3. `CLOVA OCR` 서비스 계정을 생성하고, `Secret Key` 와 `Invoke URL` 을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 결과 ROI 도식화를 위한 라이브러리 설치\n",
    "%pip install opencv-python\n",
    "# %pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "import cv2\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_URL = os.getenv('CLOVA_OCR_INVOKE URL')\n",
    "SECRET_KEY =  os.getenv('CLOVA_OCR_API_KEY')\n",
    "IMAGE_PATH = '이미지 경로 설정'  \n",
    "\n",
    "with open(IMAGE_PATH, 'rb') as f:\n",
    "    image_data = base64.b64encode(f.read()).decode()\n",
    "\n",
    "payload = {\n",
    "    'version': 'V2',\n",
    "    'requestId': str(uuid.uuid4()),\n",
    "    'timestamp': int(time.time() * 1000),\n",
    "    'images': [\n",
    "        {\n",
    "            'name': 'sample',\n",
    "            'format': 'jpg',\n",
    "            'data': image_data\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'X-OCR-SECRET': SECRET_KEY,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "result = response.json()\n",
    "\n",
    "if 'images' in result:\n",
    "    fields = result['images'][0].get('fields', [])\n",
    "    print('--- 인식된 텍스트 ---')\n",
    "    print(''.join([field['inferText'] for field in fields]))\n",
    "else:\n",
    "    print('응답 형식이 예상과 다릅니다:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plt_imshow(title='image', img=None, figsize=(8 ,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    " \n",
    "    if type(img) == list:\n",
    "        if type(title) == list:\n",
    "            titles = title\n",
    "        else:\n",
    "            titles = []\n",
    " \n",
    "            for i in range(len(img)):\n",
    "                titles.append(title)\n",
    " \n",
    "        for i in range(len(img)):\n",
    "            if len(img[i].shape) <= 2:\n",
    "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_GRAY2RGB)\n",
    "            else:\n",
    "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)\n",
    " \n",
    "            plt.subplot(1, len(img), i + 1), plt.imshow(rgbImg)\n",
    "            plt.title(titles[i])\n",
    "            plt.xticks([]), plt.yticks([])\n",
    " \n",
    "        plt.show()\n",
    "    else:\n",
    "        if len(img.shape) < 3:\n",
    "            rgbImg = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        else:\n",
    "            rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "        plt.imshow(rgbImg)\n",
    "        plt.title(title)\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import platform\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "def put_text(image, text, x, y, color=(0, 255, 0), font_size=22):\n",
    "    if type(image) == np.ndarray:\n",
    "        color_coverted = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(color_coverted)\n",
    " \n",
    "    if platform.system() == 'Darwin':\n",
    "        font = 'AppleGothic.ttf'\n",
    "    elif platform.system() == 'Windows':\n",
    "        font = 'malgun.ttf'\n",
    "        \n",
    "    image_font = ImageFont.truetype(font, font_size)\n",
    "    font = ImageFont.load_default()\n",
    "    draw = ImageDraw.Draw(image)\n",
    " \n",
    "    draw.text((x, y), text, font=image_font, fill=color)\n",
    "    \n",
    "    numpy_image = np.array(image)\n",
    "    opencv_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
    " \n",
    "    return opencv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "roi_img = img.copy()\n",
    " \n",
    "for field in result['images'][0]['fields']:\n",
    "    text = field['inferText']\n",
    "    vertices_list = field['boundingPoly']['vertices']\n",
    "    pts = [tuple(vertice.values()) for vertice in vertices_list]\n",
    "    topLeft = [int(_) for _ in pts[0]]\n",
    "    topRight = [int(_) for _ in pts[1]]\n",
    "    bottomRight = [int(_) for _ in pts[2]]\n",
    "    bottomLeft = [int(_) for _ in pts[3]]\n",
    " \n",
    "    cv2.line(roi_img, topLeft, topRight, (0,255,0), 2)\n",
    "    cv2.line(roi_img, topRight, bottomRight, (0,255,0), 2)\n",
    "    cv2.line(roi_img, bottomRight, bottomLeft, (0,255,0), 2)\n",
    "    cv2.line(roi_img, bottomLeft, topLeft, (0,255,0), 2)\n",
    "    roi_img = put_text(roi_img, text, topLeft[0], topLeft[1] - 10, font_size=30)\n",
    "    \n",
    "    print(text)\n",
    " \n",
    "plt_imshow([\"Original\", \"ROI\"], [img, roi_img], figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
